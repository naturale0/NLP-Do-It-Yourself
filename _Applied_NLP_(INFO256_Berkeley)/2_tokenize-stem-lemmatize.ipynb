{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "egyptian-combat",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Words\" data-toc-modified-id=\"Words-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Words</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lecture\" data-toc-modified-id=\"Lecture-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Lecture</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tokenization\" data-toc-modified-id=\"Tokenization-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Tokenization</a></span></li><li><span><a href=\"#Stemming-/-Lemmatization\" data-toc-modified-id=\"Stemming-/-Lemmatization-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Stemming / Lemmatization</a></span></li></ul></li><li><span><a href=\"#Readings\" data-toc-modified-id=\"Readings-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Readings</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "isolated-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "text = \"As much mud in the streets as if the waters \\\n",
    "had but newly retired from the face of the earth, \\\n",
    "and it would not be wonderful to meet a Megalosaurus, \\\n",
    "forty feet long or so, waddling like an elephantine \\\n",
    "lizard up Holborn Hill.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-helena",
   "metadata": {},
   "source": [
    "# Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-commander",
   "metadata": {},
   "source": [
    "## Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-invasion",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-organizer",
   "metadata": {},
   "source": [
    "* 단어를 형태소(token) 단위로 쪼갠다\n",
    "* `.`, `\"`, `n't` 등을 독립적인 토큰으로 쪼갠다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-isaac",
   "metadata": {},
   "source": [
    "Sentiment analysis accuracy (even on IMDB data) can vary by ~5 points as a function of tokenization choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-cycle",
   "metadata": {},
   "source": [
    "```python\n",
    "nltk.download('punkt')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "iraqi-underwear",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As', 'much', 'mud', 'in', 'the', 'streets', 'as', 'if', 'the', 'waters']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [token.text for token in nlp(text)]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "descending-treasury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As', 'much', 'mud', 'in', 'the', 'streets', 'as', 'if', 'the', 'waters']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text)  # use Punkt tokenizer\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-classics",
   "metadata": {},
   "source": [
    "### Stemming / Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-lawyer",
   "metadata": {},
   "source": [
    "* stem: 단어를 단순히 어근과 비슷해지도록 자른다 (organized, organizing -> organiz)\n",
    "* lemmatize: 단어의 형태를 분석하여 어근을 탐색 (-> organize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "geological-malawi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['as', 'much', 'mud', 'in', 'the', 'street', 'as', 'if', 'the', 'water']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = [token.lemma_ for token in nlp(text)]\n",
    "lemmas[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "incident-monte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As', 'much', 'mud', 'in', 'the', 'street', 'as', 'if', 'the', 'water']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "[stemmer.stem(token) for token in tokens][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-crest",
   "metadata": {},
   "source": [
    "## Readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "straight-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "reverse-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"http://www.gutenberg.org/files/2554/2554-0.txt\",)\n",
    "\n",
    "response.encoding = \"utf8\"\n",
    "raw = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-walnut",
   "metadata": {},
   "source": [
    "tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "individual-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-redhead",
   "metadata": {},
   "source": [
    "`nltk.Text`: similar to `spacy.load`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "solved-spring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: ﻿The Project Gutenberg EBook of Crime and Punishment...>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "british-exclusive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe', 'Project', 'Gutenberg', 'EBook', 'of']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "constitutional-challenge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Katerina', 'Ivanovna'), ('Pyotr', 'Petrovitch'), ('Pulcheria', 'Alexandrovna'), ('Avdotya', 'Romanovna'), ('Rodion', 'Romanovitch'), ('Marfa', 'Petrovna'), ('Sofya', 'Semyonovna'), ('old', 'woman'), ('Project', 'Gutenberg-tm'), ('Porfiry', 'Petrovitch'), ('Amalia', 'Ivanovna'), ('great', 'deal'), ('young', 'man'), ('Nikodim', 'Fomitch'), ('Ilya', 'Petrovitch'), ('Project', 'Gutenberg'), ('Andrey', 'Semyonovitch'), ('Hay', 'Market'), ('Dmitri', 'Prokofitch'), ('Good', 'heavens')] \n",
      "\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Ilya Petrovitch; Project\n",
      "Gutenberg; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(text.collocation_list(), \"\\n\")\n",
    "print(text.collocations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-workplace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_x86",
   "language": "python",
   "name": "pytorch_x86"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": "2",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
