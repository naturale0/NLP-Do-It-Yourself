{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "synthetic-matter",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Simple Sentiment Analysis<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preprocess-the-data\" data-toc-modified-id=\"Preprocess-the-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocess the data</a></span></li><li><span><a href=\"#Create-the-model\" data-toc-modified-id=\"Create-the-model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Create the model</a></span></li><li><span><a href=\"#Train-the-model\" data-toc-modified-id=\"Train-the-model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Train the model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-promotion",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cardiac-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-carpet",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-vitamin",
   "metadata": {},
   "source": [
    "The parameters of a [`torchtext.data.Field`](https://torchtext.readthedocs.io/en/latest/data.html) specify how the data should be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-replica",
   "metadata": {},
   "source": [
    "`Field` class models common text processing datatypes that can be represented\n",
    "by tensors.  It holds a `Vocab` object that defines the set of possible values\n",
    "for elements of the field and their corresponding numerical representations.\n",
    "The `Field` object also holds other parameters relating to how a datatype\n",
    "should be numericalized, such as a tokenization method and the kind of\n",
    "Tensor that should be produced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-concentration",
   "metadata": {},
   "source": [
    "* Our `TEXT` field has `tokenize='spacy'` as an argument. This defines that the \"tokenization\" (the act of splitting the string into discrete \"tokens\") should be done using the spaCy tokenizer. If no tokenize argument is passed, the default is simply splitting the string on spaces.\n",
    "* `LABEL` is defined by a `LabelField`, a special subset of the `Field` class specifically used for handling labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exciting-crime",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PSH/miniforge3_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/PSH/miniforge3_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "TEXT = torchtext.data.Field(tokenize=\"spacy\")         # tokenize text with spacy\n",
    "LABEL = torchtext.data.LabelField(dtype=torch.float)  # convert type of label to torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-mortgage",
   "metadata": {},
   "source": [
    "Load IMDB data with `torchtext`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "immediate-drive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [01:38<00:00, 856kB/s] \n",
      "/Users/PSH/miniforge3_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = torchtext.datasets.IMDB.splits(TEXT, LABEL, root=\"/Users/PSH/Downloads/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "respective-allergy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "brown-league",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['For', 'a', 'movie', 'that', 'gets', 'no', 'respect', 'there', 'sure', 'are', 'a', 'lot', 'of', 'memorable', 'quotes', 'listed', 'for', 'this', 'gem', '.', 'Imagine', 'a', 'movie', 'where', 'Joe', 'Piscopo', 'is', 'actually', 'funny', '!', 'Maureen', 'Stapleton', 'is', 'a', 'scene', 'stealer', '.', 'The', 'Moroni', 'character', 'is', 'an', 'absolute', 'scream', '.', 'Watch', 'for', 'Alan', '\"', 'The', 'Skipper', '\"', 'Hale', 'jr', '.', 'as', 'a', 'police', 'Sgt', '.']\n",
      "pos\n"
     ]
    }
   ],
   "source": [
    "print(trainset.examples[0].text)\n",
    "print(trainset.examples[0].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-bosnia",
   "metadata": {},
   "source": [
    "Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lined-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "trainset, validset = trainset.split(random_state=random.seed(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "internal-destination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 7500, 25000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(validset), len(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-lawsuit",
   "metadata": {},
   "source": [
    "**Create vobabulary**\n",
    "\n",
    "There are two ways effectively cut down our vocabulary, we can either only take the top $n$ most common words or ignore words that appear less than $m$ times. We'll do the former, only keeping the top 25,000 words.\n",
    "\n",
    "What do we do with words that appear in examples but we have cut from the vocabulary? We replace them with a special unknown or `<unk>` token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "subjective-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(trainset, max_size=MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "conventional-peace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25002, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab), len(LABEL.vocab)  # 25002, because of <unk> and <pad>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-anaheim",
   "metadata": {},
   "source": [
    "To ensure each sentence in the batch is the same size, any shorter than the longest within the batch are padded with `<pad>`.\n",
    "\n",
    "![pad.png](https://github.com/bentrevett/pytorch-sentiment-analysis/raw/3cea8e83b83166845e5fb08ad753571437c683ed/assets/sentiment6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "destroyed-compound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 201836),\n",
       " (',', 192304),\n",
       " ('.', 165424),\n",
       " ('and', 109492),\n",
       " ('a', 109202),\n",
       " ('of', 100450),\n",
       " ('to', 93564),\n",
       " ('is', 76411),\n",
       " ('in', 61395),\n",
       " ('I', 53909)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-calendar",
   "metadata": {},
   "source": [
    "`stoi` (string to int) or `itos` (int to string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "controlling-purple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "generic-commons",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "890"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi[\"nature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "extended-indiana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'pos': 0, 'neg': 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-delicious",
   "metadata": {},
   "source": [
    "We'll use a `BucketIterator` which is a special type of iterator that will return a batch of examples where each example is of a similar length, minimizing the amount of padding per example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-hearing",
   "metadata": {},
   "source": [
    "(place the tensors returned by the iterator on the GPU (if you're using one). PyTorch handles this using `torch.device`, we then pass this device to the iterator.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "compressed-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "guilty-retrieval",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PSH/miniforge3_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "trainiter, validiter, testiter = torchtext.data.BucketIterator.splits(\n",
    "    (trainset, validset, testset),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-phenomenon",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "manufactured-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "checked-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSentimentCLassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(SimpleSentimentCLassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, x = self.rnn(x)  # many-to-one model\n",
    "        \n",
    "        x = x.squeeze(0)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-official",
   "metadata": {},
   "source": [
    "create instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "surgical-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "crazy-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleSentimentCLassifier(\n",
    "    VOCAB_SIZE,\n",
    "    EMBEDDING_DIM,\n",
    "    HIDDEN_DIM,\n",
    "    OUTPUT_DIM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "average-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,592,105 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{n_params:,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-judge",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-veteran",
   "metadata": {},
   "source": [
    "The `BCEWithLogitsLoss` criterion carries out both the sigmoid and the binary cross entropy steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "legal-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "classified-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "intimate-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "nutritional-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(pred, target):\n",
    "    pred = torch.round(torch.sigmoid(pred))\n",
    "    correct = (pred == target).float()\n",
    "    return correct.sum() / len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "certain-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    loss_epoch = 0.\n",
    "    acc_epoch = 0.\n",
    "    \n",
    "    # set the model to train mode.\n",
    "    # dropout, batchnorm, ... will be turned on.\n",
    "    model.train()\n",
    "    \n",
    "    # per batch training\n",
    "    for batch in iterator:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        out = model(batch.text).squeeze(1)\n",
    "        loss = criterion(out, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_epoch += loss.item()\n",
    "        acc_epoch += binary_accuracy(out, batch.label)\n",
    "    \n",
    "    return loss_epoch / len(iterator),\\\n",
    "           acc_epoch / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "portuguese-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    loss_epoch = 0.\n",
    "    acc_epoch = 0.\n",
    "    \n",
    "    # set the model to evaluation mode.\n",
    "    # dropout, batchnorm, ... will be turned off.\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():  # pause gradient calculation\n",
    "        for batch in iterator:\n",
    "            out = model(batch.text).squeeze(1)\n",
    "            loss = criterion(out, batch.label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_epoch += loss.item()\n",
    "            acc_epoch += binary_accuracy(out, batch.label)\n",
    "    \n",
    "    return loss_epoch / len(iterator),\\\n",
    "           acc_epoch / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "twelve-malaysia",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-b02d9dc2abb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaliditer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train loss: {train_loss: .3f} | train acc: {train_Acc: .3f} | val. loss: {valid_loss: .3f} | val. acc: {valid_acc: .3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-eee5fab00213>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCH = 10\n",
    "\n",
    "for i in range(1, N_EPOCH+1):\n",
    "    train_loss, train_acc = train(model, trainiter, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, validiter, criterion)\n",
    "    print(f\"train loss: {train_loss: .3f} | train acc: {train_Acc: .3f} | val. loss: {valid_loss: .3f} | val. acc: {valid_acc: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-remove",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_x86",
   "language": "python",
   "name": "pytorch_x86"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "208.24728393554688px",
    "width": "187.9891357421875px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Simple Sentiment Analysis",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
