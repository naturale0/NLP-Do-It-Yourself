{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "manufactured-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchtext\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-painting",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>3-2. ELMo<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Prepare-dataset:-IMBD\" data-toc-modified-id=\"Prepare-dataset:-IMBD-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Prepare dataset: IMBD</a></span><ul class=\"toc-item\"><li><span><a href=\"#For-pretraining\" data-toc-modified-id=\"For-pretraining-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>For pretraining</a></span></li><li><span><a href=\"#For-training\" data-toc-modified-id=\"For-training-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>For training</a></span></li></ul></li><li><span><a href=\"#Build-the-model\" data-toc-modified-id=\"Build-the-model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Build the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bidirectional-language-model\" data-toc-modified-id=\"Bidirectional-language-model-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Bidirectional language model</a></span></li><li><span><a href=\"#ELMo\" data-toc-modified-id=\"ELMo-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>ELMo</a></span></li></ul></li><li><span><a href=\"#Train-the-model\" data-toc-modified-id=\"Train-the-model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Train the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pretrain-bidirectional-language-model\" data-toc-modified-id=\"Pretrain-bidirectional-language-model-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Pretrain bidirectional language model</a></span></li><li><span><a href=\"#Train-ELMo-for-sentiment-analysis\" data-toc-modified-id=\"Train-ELMo-for-sentiment-analysis-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Train ELMo for sentiment analysis</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-siemens",
   "metadata": {},
   "source": [
    "## Prepare dataset: IMBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prepared-means",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [02:08<00:00, 654kB/s] \n",
      "100%|██████████| 25000/25000 [00:24<00:00, 1028.00lines/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.experimental.datasets import IMDB\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer(\"spacy\")\n",
    "train, test = IMDB(tokenizer=tokenizer, root=\"~/torchdata/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "taken-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocab = train.get_vocab()\n",
    "\n",
    "v = Counter(['<s>', '</s>'])\n",
    "v = torchtext.vocab.Vocab(v, specials=['<s>', '</s>'])\n",
    "vocab.extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "enhanced-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "attractive-taiwan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:47<00:00, 527.94it/s]\n"
     ]
    }
   ],
   "source": [
    "ngrams = 2\n",
    "bos = \"<s>\"\n",
    "eos = \"</s>\"\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for _, words in tqdm(train):\n",
    "    # Begin-of-sentence token\n",
    "    x.append([vocab.stoi[bos]] + words[0:ngrams-1].tolist())\n",
    "    y.append(words[ngrams-1].item())\n",
    "    \n",
    "    # in-sentence tokens\n",
    "    for i in range(len(words)-ngrams):\n",
    "        text = words[i:i+ngrams]\n",
    "        label = words[i+ngrams]\n",
    "        x.append(text.tolist())\n",
    "        y.append(label.tolist())\n",
    "        \n",
    "    # End-of-sentence token\n",
    "    x.append(words[i+1:i+ngrams].tolist() + [vocab.stoi[eos]])\n",
    "    y.append(vocab.stoi[eos])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-liver",
   "metadata": {},
   "source": [
    "```python\n",
    "with open(\"./IMBD_bigram.json\", \"w\") as w:\n",
    "    json.dump({\"data\": x, \"label\": y}, w)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-jersey",
   "metadata": {},
   "source": [
    "### For pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-dating",
   "metadata": {},
   "source": [
    "* transform to character-level n-gram dataset\n",
    "    * original script\n",
    "```\n",
    "%load https://gist.githubusercontent.com/akurniawan/30719686669dced49e7ced720329a616/raw/7b9f9967c01ce87ac505520a5aa58d3b24c55c66/translation_char_example.py\n",
    "```\n",
    "    * modified\n",
    "```\n",
    "%load https://gist.github.com/naturale0/6bb3b8a5c682bd281de87e408fa71bf1/raw/df8b7e198f149f81c4f72af977760b2eb3226cdf/translation_char_example.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "seasonal-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified a little to fit classification\n",
    "import itertools\n",
    "from torchtext.experimental.datasets import TextClassificationDataset\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.experimental.functional import sequential_transforms\n",
    "\n",
    "def build_char_vocab(data, index, \n",
    "                     bow=\"<w>\", eow=\"</w>\",\n",
    "                     bos=\"<s>\", eos=\"</s>\"):\n",
    "    \"\"\"\n",
    "    build character level vocabulary\n",
    "    \"\"\"\n",
    "    tok_list = [\n",
    "        [bow],\n",
    "        [eow],\n",
    "        [bos],\n",
    "        [eos],\n",
    "    ]\n",
    "    for line in data:\n",
    "        tokens = list(itertools.chain.from_iterable(line[index]))\n",
    "        tok_list.append(tokens)\n",
    "    return build_vocab_from_iterator(tok_list)\n",
    "\n",
    "\n",
    "def stoi(vocab):\n",
    "    \"\"\"\n",
    "    change string to index\n",
    "    \"\"\"\n",
    "    def func(tok_iter):\n",
    "        return [[vocab[char] for char in word]\\\n",
    "                for word in tok_iter]\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "def tokenize_char(bow=\"<w>\", eow=\"</w>\", \n",
    "                  bos=\"<s>\", eos=\"</s>\",\n",
    "                  max_word_length=20):\n",
    "    \"\"\"\n",
    "    attach bow, eow token and pad with token\n",
    "    \"\"\"\n",
    "    def func(tok_iter):\n",
    "        result = np.empty((ngrams, max_word_length+2), dtype=object)\n",
    "        result[:] = \"<pad>\"\n",
    "        \n",
    "        for i, word in enumerate(tok_iter):\n",
    "            if \"\".join(word) == \"<s>\":\n",
    "                # Begin-of-sentence token\n",
    "                result[i, :3] = [bow, bos, eow] #+ [\"<pad>\"] * (max_word_length - 1)\n",
    "            elif \"\".join(word) == \"</s>\":\n",
    "                # End-of-sentence token\n",
    "                result[i, :3] = [bow, eos, eow] #+ [\"<pad>\"] * (max_word_length - 1)\n",
    "            else:\n",
    "                # in-sentence words\n",
    "                if len(word) < max_word_length:\n",
    "                    result[i, :len(word)+2] = [bow] + word + [eow]\n",
    "                else:\n",
    "                    result[i, :] = [bow] + word[:max_word_length] + [eow]\n",
    "                \n",
    "                \n",
    "#                 result[:len(tok_iter)] = [\n",
    "#                     [bow] + word + [eow] \\\n",
    "#                     + [\"<pad>\"] * (max_word_length - len(word)) \\\n",
    "#                     if len(word) < max_word_length \\\n",
    "#                     else [bow] + word[:max_word_length] + [eow]\n",
    "#                 for word in tok_iter]\n",
    "\n",
    "        return result\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "desirable-certification",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6810715it [00:07, 935578.38it/s] \n"
     ]
    }
   ],
   "source": [
    "# Cache training data for vocabulary construction\n",
    "train_data = [(line[0], [vocab.itos[ix] for ix in line[1]]) for line in tqdm(zip(y, x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "noticed-netscape",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1657, ['<s>', 'I']), (11, ['I', 'rented']), (14567, ['rented', 'I'])]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "drawn-mainstream",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6810719lines [00:07, 908319.44lines/s]\n"
     ]
    }
   ],
   "source": [
    "# Setup vocabularies (both words and chars)\n",
    "char_vocab = build_char_vocab(train_data, index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "multiple-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the dataset with character level tokenization\n",
    "def char_tokenizer(words):\n",
    "    return [list(word) for word in words]\n",
    "\n",
    "char_transform = sequential_transforms(\n",
    "    char_tokenizer, \n",
    "    tokenize_char(), \n",
    "    stoi(char_vocab),\n",
    "    lambda x: torch.tensor(x)\n",
    ")\n",
    "\n",
    "trainset = TextClassificationDataset(\n",
    "    train_data,\n",
    "    char_vocab,\n",
    "    (lambda x: x, char_transform),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "parallel-patient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<w>', 's', 'u', 'r', 'r', 'o', 'u', 'n', 'd', 'e', 'd', '</w>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "print([[char_vocab.itos[i] for i in w] for w in trainset[17][1]] [1][:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "regulation-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DataLoader\n",
    "def collate_fn(batch):\n",
    "    label, text = zip(*batch)\n",
    "    label = torch.LongTensor(label)\n",
    "    text = torch.stack(text)\n",
    "    #lens = list(map(lambda x: len(x[(x != 0).all(dim=1)]), text))\n",
    "    \n",
    "    return label, text\n",
    "\n",
    "pretrainloader = data.DataLoader(trainset, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "southeast-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = next(iter(pretrainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-brazilian",
   "metadata": {},
   "source": [
    "### For training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "distant-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified a little to fit classification\n",
    "import itertools\n",
    "from torchtext.experimental.datasets import TextClassificationDataset\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.experimental.functional import sequential_transforms\n",
    "\n",
    "def build_char_vocab(data, index, bow=\"<w>\", eow=\"</w>\"):\n",
    "    \"\"\"\n",
    "    build character level vocabulary\n",
    "    \"\"\"\n",
    "    tok_list = [\n",
    "        [bow],\n",
    "        [eow],\n",
    "    ]\n",
    "    for line in data:\n",
    "        tokens = list(itertools.chain.from_iterable(line[index]))\n",
    "        tok_list.append(tokens)\n",
    "    return build_vocab_from_iterator(tok_list)\n",
    "\n",
    "\n",
    "def stoi(vocab):\n",
    "    \"\"\"\n",
    "    change string to index\n",
    "    \"\"\"\n",
    "    def func(tok_iter):\n",
    "        return [[vocab[char] for char in word]\\\n",
    "                for word in tok_iter]\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "def tokenize_char(bow=\"<w>\", eow=\"</w>\", max_word_length=20):\n",
    "    \"\"\"\n",
    "    attach bow, eow token and pad with token\n",
    "    \"\"\"\n",
    "    def func(tok_iter):\n",
    "        result = np.empty((max(len_seq), max_word_length+2), dtype=object)\n",
    "        \n",
    "        # \"≥\" for padding\n",
    "        result[:len(tok_iter)] = [\n",
    "            [bow] + word + [eow] \\\n",
    "            + [\"<pad>\"] * (max_word_length - len(word)) \\\n",
    "            if len(word) < max_word_length \\\n",
    "            else [bow] + word[:max_word_length] + [eow]\n",
    "        for word in tok_iter]\n",
    "        \n",
    "        return result\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "diverse-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache training data for vocabulary construction\n",
    "train_data = [(line[0], [vocab.itos[ix] for ix in line[1]]) for line in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "optical-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store list of seq length for packing later\n",
    "len_seq = list(map(lambda x: len(x[1]), train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "significant-baghdad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6760717lines [00:05, 1185785.41lines/s]\n"
     ]
    }
   ],
   "source": [
    "# Setup vocabularies (both words and chars)\n",
    "char_vocab = build_char_vocab(train_data, index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "based-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the dataset with character level tokenization\n",
    "def char_tokenizer(words):\n",
    "    return [list(word) for word in words]\n",
    "\n",
    "char_transform = sequential_transforms(\n",
    "    char_tokenizer, \n",
    "    tokenize_char(), \n",
    "    stoi(char_vocab),\n",
    "    lambda x: torch.tensor(x)\n",
    ")\n",
    "\n",
    "trainset = TextClassificationDataset(\n",
    "    train_data,\n",
    "    char_vocab,\n",
    "    (lambda x: x, char_transform),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "adolescent-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DataLoader\n",
    "def collate_fn(batch):\n",
    "    label, text = zip(*batch)\n",
    "    label = torch.stack(label)\n",
    "    text = torch.stack(text)\n",
    "    #lens = list(map(lambda x: len(x[(x != 0).all(dim=1)]), text))\n",
    "    \n",
    "    return label, text\n",
    "\n",
    "trainloader = data.DataLoader(trainset, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-fight",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-chassis",
   "metadata": {},
   "source": [
    "### Bidirectional language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "addressed-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharConv(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CharConv, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        CHAR_EMBEDDING_DIM = 16\n",
    "        self.char_embedding = nn.Embedding(len(char_vocab), CHAR_EMBEDDING_DIM)\n",
    "        \n",
    "        # Conv layers\n",
    "        self.convs = [\n",
    "            nn.Conv2d(CHAR_EMBEDDING_DIM, 4, 1),\n",
    "            nn.Conv2d(CHAR_EMBEDDING_DIM, 4, (1, 2)),\n",
    "            nn.Conv2d(CHAR_EMBEDDING_DIM, 8, (1, 3)),\n",
    "            nn.Conv2d(CHAR_EMBEDDING_DIM, 16, (1, 4)),\n",
    "            nn.Conv2d(CHAR_EMBEDDING_DIM, 32, (1, 5)),\n",
    "            nn.Conv2d(CHAR_EMBEDDING_DIM, 64, (1, 6)),\n",
    "            nn.Conv2d(CHAR_EMBEDDING_DIM, 128, (1, 7))\n",
    "        ]\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # character-level convolution\n",
    "        x = self.char_embedding(x).permute(0,3,1,2)\n",
    "        x = [conv(x) for conv in self.convs]\n",
    "        x = [F.max_pool2d(x_c, kernel_size=(1, x_c.shape[3])) for x_c in x]\n",
    "        x = [torch.squeeze(x_p) for x_p in x]\n",
    "        x = torch.hstack(x)  # 1, n_batch, concat_length\n",
    "        #x = x.view(2, 0, 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "raising-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        # Bi-LSTM\n",
    "        self.lstm1 = nn.LSTM(256, 1024, bidirectional=True)\n",
    "        self.proj = nn.Linear(2*1024, 2*256, bias=False)\n",
    "        self.lstm2 = nn.LSTM(2*256, 1024, bidirectional=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # reshape input\n",
    "        x = x.view(-1, 256, ngrams).permute(2, 0, 1)\n",
    "        \n",
    "        # 1st LSTM layer\n",
    "        o, (h1, __) = self.lstm1(x)\n",
    "        \n",
    "        # main connection\n",
    "        p = self.proj(o)\n",
    "        \n",
    "        # skip connection\n",
    "        x2 = x.repeat(1,1,2)\n",
    "        x3 = x2 + p\n",
    "        \n",
    "        # 2nd LSTM layer\n",
    "        _, (h2, __) = self.lstm2(x3)\n",
    "        return h1, h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "artificial-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLangModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional language model (will be pretrained)\n",
    "    \"\"\"\n",
    "    def __init__(self, char_cnn, bi_lstm):\n",
    "        super(BiLangModel, self).__init__()\n",
    "        \n",
    "        # Highway connection\n",
    "        CHAR_EMBEDDING_DIM = 16\n",
    "        self.highway = nn.Linear(ngrams * 256, ngrams * 256)\n",
    "        self.transform = nn.Linear(ngrams * 256, ngrams * 256)\n",
    "        self.char_cnn = char_cnn\n",
    "        self.bi_lstm = bi_lstm\n",
    "        \n",
    "        # last layer: classifier\n",
    "        self.fc = nn.Linear(ngrams * 1024, 1024)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Character-level convolution\n",
    "        x = self.char_cnn(x)\n",
    "        x = x.view(-1, ngrams*256)\n",
    "        \n",
    "        # highway\n",
    "        h = self.highway(x)\n",
    "        t_gate = torch.sigmoid(self.transform(x))\n",
    "        c_gate = 1 - t_gate\n",
    "        x = h * t_gate + x * c_gate\n",
    "        \n",
    "        # Bi-LSTM\n",
    "        _, x = self.bi_lstm(x)\n",
    "        \n",
    "        # fully-connected layer (classify)\n",
    "        x = x.view(-1, ngrams * 1024)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "raising-chassis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charconv = CharConv()\n",
    "bilstm = BiLSTM()\n",
    "bilm = BiLangModel(charconv, bilstm)\n",
    "bilm(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "sustainable-person",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BiLanguageModel.png'"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "charconv = CharConv()\n",
    "bilstm = BiLSTM()\n",
    "\n",
    "model = BiLangModel(charconv, bilstm)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.AdaptiveLogSoftmaxWithLoss(1024, VOCAB_SIZE, cutoffs=[10, 100, 1000, 10000])\n",
    "\n",
    "make_dot(criterion(model(x), y).loss).render(\"BiLanguageModel\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-complement",
   "metadata": {},
   "source": [
    "### ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-estate",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-disaster",
   "metadata": {},
   "source": [
    "### Pretrain bidirectional language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "exceptional-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "personal-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "celtic-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, y):\n",
    "    with torch.no_grad():\n",
    "        pred = criterion.log_prob(output).argmax(dim=1)\n",
    "    correct = (pred == y).float()\n",
    "    #print(pred.shape, correct.shape)\n",
    "    return correct.sum() / len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "julian-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer):\n",
    "    loss_epoch = 0.\n",
    "    acc_epoch = 0.\n",
    "    for y, x in dataloader:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        out = model(x)\n",
    "        loss = criterion(out, y).loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_epoch += loss.item()\n",
    "        acc_epoch += accuracy(out, y).item()\n",
    "    return loss_epoch, acc_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "waiting-shape",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-437-3da53a64e221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-436-b46aec085cf1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, criterion, optimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-384-ea1b9560ecf0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Bi-LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbi_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# fully-connected layer (classify)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-381-2e7e9a8d0d90>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# 2nd LSTM layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3_x86_64/envs/pytorch_x86/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    662\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCH = 2\n",
    "\n",
    "losses = []\n",
    "accs = []\n",
    "for i in range(1, N_EPOCH+1):\n",
    "    loss_epoch, acc_epoch = train(model, pretrainloader, criterion, optimizer)\n",
    "    losses.append(loss_epoch)\n",
    "    accs.append(acc_epoch)\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        print(f\"epoch: {i:03}, loss: {loss_epoch/len(trainiter): .3f}, acc: {acc_epoch/len(trainiter): .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-bibliography",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-platinum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-corner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ruled-natural",
   "metadata": {},
   "source": [
    "### Train ELMo for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-watch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-local",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-basics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-bolivia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-lancaster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-boating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-afternoon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-commerce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_x86",
   "language": "python",
   "name": "pytorch_x86"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "3-2. ELMo",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
